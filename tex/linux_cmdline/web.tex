\section{web}

\noindent Скачать весь сайт: \\
\cn{\$wget -r -k -l 7 -p -E -nc http://site.com/}
\cci{-r}{рекурсивно переходить по ссылкам на сайте;}
\cci{-k}{преобразовать все ссылки в файлах в локальные;}
\cci{-p}{загрузить все файлы (изображения, css и т.д.);}
\cci{-l}{максимальная глубину рекурсии (по умолчанию 5);}
\cci{-E}{добавлять к загруженным файлам расширение .html;}
\cci{-nc}{перезаписывать существующие файлы;}


\ccn{\$curl -li https://localhost}{содержимое сайта}

\noindent Парсинг страницы html по классам объектов: \\
\ci{\$curl -s https://efficientlinux.com/areacodes.html $\backslash$ }
\ci{\indent| hxnormalize -x $\backslash$}
\ci{\indent| hxselect -c -s@ '\#ac .ac, \#ac .state, \#ac .cities'}

\cn{\$lynx -dump https://efficientlinux.com/areacodes.htm}
